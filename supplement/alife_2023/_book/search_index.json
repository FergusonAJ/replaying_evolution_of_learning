[["index.html", "Supplement for: “Potentiating Mutations Facilitate the Evolution of Associative Learning in Digital Organisms” Section 1 Introduction", " Supplement for: “Potentiating Mutations Facilitate the Evolution of Associative Learning in Digital Organisms” Austin J. Ferguson and Charles Ofria 2023-05-20 Section 1 Introduction Here we show all additional graphs that would not fit in the paper. Please use the navigation on the left to view the different sections. For data, source code, and analyses, please refer to the GitHub repo: https://github.com/FergusonAJ/replaying_evolution_of_learning This bookdown supplement is based on Alex Lalejini’s example: https://github.com/amlalejini/auto-deploying-bookdown-example. "],["initial-200-parallel-replicates.html", "Section 2 Initial 200 parallel replicates 2.1 Dependencies 2.2 Loading data 2.3 Behavior classification summary 2.4 Accuracy plots 2.5 Raincloud plots (individual trials) 2.6 Raincloud plots (per replicate)", " Section 2 Initial 200 parallel replicates Here we plot data associated with the initial 200 replicates. All data, analysis scripts, etc. are found in the experiment directory: /experiments/alife_2023/2023_02_21_01__initial_10_cooldown/. 2.1 Dependencies # External library(ggplot2) library(dplyr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) base_repo_dir = &#39;../..&#39; exp_dir = paste0(base_repo_dir, &#39;/experiments/alife_2023/2023_02_21_01__initial_10_cooldown&#39;) # Internal source(paste0(base_repo_dir, &#39;/global_shared_files/constant_vars__three_cues_one_set.R&#39;)) source(paste0(base_repo_dir, &#39;/global_shared_files/shared_funcs__three_cues_one_set.R&#39;)) 2.2 Loading data To save time, we load the pre-processed data. To see how the data gets processed, please see ./analysis/final_dominant_analysis.R from the experiment directory. # Data for all trials from all seeds df = read.csv(paste0(exp_dir, &#39;/data/processed_data/processed_full.csv&#39;)) # One line per seed that summarizes all 100 trials df_summary = read.csv(paste0(exp_dir, &#39;/data/processed_data/processed_summary.csv&#39;)) # Sumamrize each category, e.g., how many replicates evolved error correction? classification_summary = read.csv(paste0(exp_dir, &#39;/data/processed_data/processed_classification.csv&#39;)) 2.3 Behavior classification summary Of the 200 initial replicates, how many evolved learning? Error correction? Here we plot the number of replicates that evolved each behavior. To determine the behavior of the replicate, we analyzed the most abundant genotype at the end of evolution for each replicate. ggplot(classification_summary, aes(x = seed_classification_factor, y = count, fill = seed_classification_factor)) + geom_col() + geom_text(aes(y = count + 7, label = count), size = 4) + scale_fill_manual(values = color_map) + xlab(&#39;Classification&#39;) + ylab(&#39;Number of replicates&#39;) + theme(legend.position = &#39;none&#39;) + theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) 2.4 Accuracy plots Next, we’ll look at the accuracy (number of non-backwards movements correct / non-backwards movements taken) for each replicate. Order the points by mean accuracy. df_summary = df_summary[order(df_summary$accuracy_mean),] df_summary$seed_order = 1:nrow(df_summary) df$seed_order = NA for(seed in unique(df$seed)){ df[df$seed == seed,]$seed_order = df_summary[df_summary$seed == seed,]$seed_order } For each replicate, plot mean accuracy as a solid point and min/max as partially transparent points. ggplot(df_summary, aes(x = seed_order, color = seed_classification)) + geom_point(aes(y = accuracy_mean)) + geom_point(aes(y = accuracy_min), alpha = 0.2) + geom_point(aes(y = accuracy_max), alpha = 0.2) + scale_color_manual(values = color_map) + xlab(&#39;Replicates (ordered)&#39;) + ylab(&#39;Accuracy&#39;) + #theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) Now plot the accuracy of each sample, maintaining the same order on the x-axis. ggplot(df, aes(x = seed_order, y = accuracy, color = seed_classification)) + geom_point(alpha = 0.2) + scale_color_manual(values = color_map) + xlab(&#39;Replicates (ordered)&#39;) + ylab(&#39;Accuracy&#39;) + #theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) 2.5 Raincloud plots (individual trials) Now, we look at accuracy and merit of individual trials, grouped only by behavior. Thus, all points are individual trials. # Raincloud plot of accuracy ggplot(df, aes(x = seed_classification_factor, y = accuracy, fill = seed_classification_factor)) + geom_flat_violin(scale=&quot;width&quot;, position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point(mapping=aes(color=seed_classification_factor), position = position_jitter(width = .15, height = 0), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_fill_manual(values = color_map) + scale_color_manual(values = color_map) + xlab(&#39;Classification&#39;) + ylab(&#39;Accuracy&#39;) + theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + theme(legend.position = &#39;none&#39;) Note that merit is plotted on a logarithmic (base 2) scale: # Raincloud plot of merit ggplot(df, aes(x = seed_classification_factor, y = merit, fill = seed_classification_factor)) + geom_flat_violin(scale=&quot;width&quot;, position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point(mapping=aes(color=seed_classification_factor), position = position_jitter(width = .15, height = 0), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_fill_manual(values = color_map) + scale_color_manual(values = color_map) + scale_y_continuous(trans = &#39;log2&#39;) + xlab(&#39;Classification&#39;) + ylab(&#39;Merit&#39;) + theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + theme(legend.position = &#39;none&#39;) 2.6 Raincloud plots (per replicate) Finally, we again use raincloud plots, but here we look at replicates instead of individual trials. Each point represents one of the initial 200 replicates. First we look at genome length (the ancestor had 100 instructions): # Raincloud plot of genome length ggplot(df_summary, aes(x = seed_classification_factor, y = genome_length, fill = seed_classification_factor)) + geom_flat_violin(scale=&quot;width&quot;, position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point(mapping=aes(color=seed_classification_factor), position = position_jitter(width = .15, height = 0), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_fill_manual(values = color_map) + scale_color_manual(values = color_map) + xlab(&#39;Classification&#39;) + ylab(&#39;Genome length&#39;) + theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + theme(legend.position = &#39;none&#39;) Next we look at the mean accuracy for each replicate: # Raincloud plot of mean accuracy of replicates ggplot(df_summary, aes(x = seed_classification_factor, y = accuracy_mean, fill = seed_classification_factor)) + geom_flat_violin(scale=&quot;width&quot;, position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point(mapping=aes(color=seed_classification_factor), position = position_jitter(width = .15, height = 0), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_fill_manual(values = color_map) + scale_color_manual(values = color_map) + scale_y_continuous(limits = c(0,1)) + xlab(&#39;Classification&#39;) + ylab(&#39;Mean accuracy&#39;) + theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + theme(legend.position = &#39;none&#39;) Finally, we look at the average merit for each replicate. Note that the y-axis is on a log2 scale. # Raincloud plot of mean merit of replicates ggplot(df_summary, aes(x = seed_classification_factor, y = merit_mean, fill = seed_classification_factor)) + geom_flat_violin(scale=&quot;width&quot;, position = position_nudge(x = .2, y = 0), alpha = .8 ) + geom_point(mapping=aes(color=seed_classification_factor), position = position_jitter(width = .15, height = 0), size = .5, alpha = 0.8 ) + geom_boxplot( width = .1, outlier.shape = NA, alpha = 0.5 ) + scale_fill_manual(values = color_map) + scale_color_manual(values = color_map) + scale_y_continuous(trans = &#39;log2&#39;) + xlab(&#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + theme(axis.text.x = element_text(angle=45, vjust = 1, hjust = 1)) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + theme(legend.position = &#39;none&#39;) "],["lineage-a-seed-86.html", "Section 3 Lineage A (Seed 86) 3.1 Dependencies 3.2 Loading data 3.3 Lineage data 3.4 Replay data", " Section 3 Lineage A (Seed 86) Here we plot more details of Lineage A than would fit in the paper. If you are looking through the experiment files, Lineage A was seed 86. All data for Lineage A can be found in the data/reps/86/ directory. 3.1 Dependencies rm(list = ls()) # External library(ggplot2) library(dplyr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) # Configuration variables base_repo_dir = &#39;../..&#39; exp_dir = paste0(base_repo_dir, &#39;/experiments/alife_2023/2023_02_21_01__initial_10_cooldown&#39;) seed = 86 potentiation_window_start = 400 potentiation_window_stop = 500 potentiation_target = 484 # Internal source(paste0(base_repo_dir, &#39;/global_shared_files/constant_vars__three_cues_one_set.R&#39;)) source(paste0(base_repo_dir, &#39;/global_shared_files/shared_funcs__three_cues_one_set.R&#39;)) 3.2 Loading data To save time, we load the pre-processed data. To see how the data gets processed, please see ./analysis/replay_analysis.R from the experiment directory. # Data for all trials from all replay replicates df = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_data.csv&#39;)) # One line per replay replicate that summarizes all 100 trials df_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_summary.csv&#39;)) # Sumamrize each category, e.g., how many replicates evolved error correction? classification_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_classification.csv&#39;)) # Also grab lineage data df_lineage = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/dominant_lineage_summary.csv&#39;)) # Because lineage data was collected on the cluster before we renamed a few classifications, rename them now! df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification_factor = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification_factor = seed_class_small df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification = seed_class_small 3.3 Lineage data While not shown in the paper due to space limitations, it is important to look at the initial replicate’s lineage and how it changes over time. The code for these plots is copied from the single_seed_lineage_analysis.R script. 3.3.1 Merit First, we look at the lineage as a whole and how average merit changes over time (note the y-axis is logarithmic) ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 0.25) + scale_y_continuous(trans = &#39;log2&#39;) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) Additionally, we can zoom in to view just the potentiation window. The vertical dashed line shows the main potentiating step, step 484, while the horizontal dashed line shows average merit at that step for easier comparisons. Note that this plot is not logarithmic. potentiation_mask = df_lineage$depth &gt;= potentiation_window_start &amp; df_lineage$depth &lt;= potentiation_window_stop target_step_merit_mean = df_lineage[df_lineage$depth == potentiation_target,]$merit_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_merit_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) We do not see substantial differences in fitness around step 484. While it may not be needed for this lineage, we can also normalize the merit based on the potentiating step. Remember that one additional correct state confers a merit bonus of 10%. Here, we can see that the fluctiations around the potentiating mutation generally fall in that +/-10% range. ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = 1), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean / target_step_merit_mean)) + geom_point(aes(y = merit_mean / target_step_merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) 3.3.2 Correct states Similarly, we can look at the number of correct states both overall and in the potentiation window: Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window (dashed lines show the main potentiating mutation): target_step_correct_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$correct_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_correct_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) We see no noticable change in the number of correct states around the potentiating mutation. 3.3.3 Incorrect states Just like our analysis of correct states, we can also look at the average incorrect states over time. By incorrect states, we mean the wrong movements while in a left, right, or forward state. Incorrect movements from a backward state are tracked separately. Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window: target_step_incorrect_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$incorrect_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_incorrect_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) 3.4 Replay data Now that we know what the lineage looks like, we can begin to break down the replay data. 3.4.1 Exploratory replays We started by seeding 50 replay replicates for every 50th step along the lineage in the window [50, 1000]. The data for step 0 comes from the initial 200 replicates. Here we show the potentiation over time for those exploratory replays: df_learning_summary = classification_summary[classification_summary$seed_classification == seed_class_learning,] df_learning_summary$lineage_classification = NA # Assign each depth its classification from the lineage data for(depth in unique(df_learning_summary$depth)){ df_learning_summary[df_learning_summary$depth == depth,]$lineage_classification = df_lineage[df_lineage$depth == depth,]$seed_classification } # Create masks mask_learning_summary_focal = df_learning_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_learning_summary_initial = df_learning_summary$depth %% 50 == 0 ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) We can then identify the potentiation window based on the points with the most potentiation gain. Here we selected steps 400-500 (green shaded region): ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) 3.4.2 Targeted replays With the potentiation window identified, we seeded targeted replays. For the targeted replays, we seeded 50 replay replicates from every step in the potetiation window. This gives us an idea of how individual steps in the phylogney affected potentiation. ggplot(df_learning_summary[mask_learning_summary_focal,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dotted&#39;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) This plot was extensively discussed in the paper, so we refrain from additional discussion here. 3.4.3 Potentiation of other behaviors While the paper focused on learning, it can be useful to see how the potentiation of other behaviors changes before learning takes over. These plots are included as inspiration for future work. mask_focal = classification_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_initial = classification_summary$depth %% 50 == 0 ggplot(classification_summary[mask_initial,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here is the same data, but plotted as an area plot: ggplot(classification_summary[mask_initial,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here are the same two plots showing the potentiation window and the targeted replays: ggplot(classification_summary[mask_focal,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) ggplot(classification_summary[mask_focal,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) "],["lineage-b-seed-4.html", "Section 4 Lineage B (Seed 4) 4.1 Dependencies 4.2 Loading data 4.3 Lineage data 4.4 Replay data", " Section 4 Lineage B (Seed 4) Here we plot more details of Lineage B than would fit in the paper. If you are looking through the experiment files, Lineage B was seed 4. All data for Lineage B can be found in the data/reps/4/ directory. 4.1 Dependencies rm(list = ls()) # External library(ggplot2) library(dplyr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) # Configuration variables base_repo_dir = &#39;../..&#39; exp_dir = paste0(base_repo_dir, &#39;/experiments/alife_2023/2023_02_21_01__initial_10_cooldown&#39;) seed = 4 potentiation_window_start = 50 potentiation_window_stop = 150 potentiation_target = 104 # Internal source(paste0(base_repo_dir, &#39;/global_shared_files/constant_vars__three_cues_one_set.R&#39;)) source(paste0(base_repo_dir, &#39;/global_shared_files/shared_funcs__three_cues_one_set.R&#39;)) 4.2 Loading data To save time, we load the pre-processed data. To see how the data gets processed, please see ./analysis/replay_analysis.R from the experiment directory. # Data for all trials from all replay replicates df = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_data.csv&#39;)) # One line per replay replicate that summarizes all 100 trials df_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_summary.csv&#39;)) # Sumamrize each category, e.g., how many replicates evolved error correction? classification_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_classification.csv&#39;)) # Also grab lineage data df_lineage = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/dominant_lineage_summary.csv&#39;)) # Because lineage data was collected on the cluster before we renamed a few classifications, rename them now! df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification_factor = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification_factor = seed_class_small df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification = seed_class_small 4.3 Lineage data While not shown in the paper due to space limitations, it is important to look at the initial replicate’s lineage and how it changes over time. The code for these plots is copied from the single_seed_lineage_analysis.R script. 4.3.1 Merit First, we look at the lineage as a whole and how average merit changes over time (note the y-axis is logarithmic) ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 0.25) + scale_y_continuous(trans = &#39;log2&#39;) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) Additionally, we can zoom in to view just the potentiation window. The vertical dashed line shows the main potentiating step, step 104, while the horizontal dashed line shows average merit at that step for easier comparisons. Note that this plot is not logarithmic. potentiation_mask = df_lineage$depth &gt;= potentiation_window_start &amp; df_lineage$depth &lt;= potentiation_window_stop target_step_merit_mean = df_lineage[df_lineage$depth == potentiation_target,]$merit_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_merit_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) We see a small increase in merit at the potentiation mutation. We can also normalize the merit based on the potentiating step. Remember that one additional correct state confers a merit bonus of 10%. We see this jump is larger than 10%. ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = 1), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean / target_step_merit_mean)) + geom_point(aes(y = merit_mean / target_step_merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) 4.3.2 Correct states Similarly, we can look at the number of correct states both overall and in the potentiation window: Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window (dashed lines show the main potentiating mutation): target_step_correct_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$correct_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_correct_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) We see also an increase in correct states at the potentiating mutation. 4.3.3 Incorrect states Just like our analysis of correct states, we can also look at the average incorrect states over time. By incorrect states, we mean the wrong movements while in a left, right, or forward state. Incorrect movements from a backward state are tracked separately. Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window: target_step_incorrect_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$incorrect_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_incorrect_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) We see that the potentiating mutation was able to increase the correct states without increasing the number of incorrect states. 4.4 Replay data Now that we know what the lineage looks like, we can begin to break down the replay data. 4.4.1 Exploratory replays We started by seeding 50 replay replicates for every 50th step along the lineage in the window [50, 1000]. The data for step 0 comes from the initial 200 replicates. Here we show the potentiation over time for those exploratory replays: df_learning_summary = classification_summary[classification_summary$seed_classification == seed_class_learning,] df_learning_summary$lineage_classification = NA # Assign each depth its classification from the lineage data for(depth in unique(df_learning_summary$depth)){ df_learning_summary[df_learning_summary$depth == depth,]$lineage_classification = df_lineage[df_lineage$depth == depth,]$seed_classification } # Create masks mask_learning_summary_focal = df_learning_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_learning_summary_initial = df_learning_summary$depth %% 50 == 0 ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) We can then identify the potentiation window based on the points with the most potentiation gain. Here we selected steps 50-150 (green shaded region): ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) 4.4.2 Targeted replays With the potentiation window identified, we seeded targeted replays. For the targeted replays, we seeded 50 replay replicates from every step in the potetiation window. This gives us an idea of how individual steps in the phylogney affected potentiation. ggplot(df_learning_summary[mask_learning_summary_focal,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dotted&#39;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) This plot was extensively discussed in the paper, so we refrain from additional discussion here. 4.4.3 Potentiation of other behaviors While the paper mostly focused on learning, it can be useful to see how the potentiation of other behaviors changes before learning takes over. These plots are included as inspiration for future work. mask_focal = classification_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_initial = classification_summary$depth %% 50 == 0 ggplot(classification_summary[mask_initial,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here is the same data, but plotted as an area plot: ggplot(classification_summary[mask_initial,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here are the same two plots showing the potentiation window and the targeted replays: ggplot(classification_summary[mask_focal,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) ggplot(classification_summary[mask_focal,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) "],["lineage-c-seed-15.html", "Section 5 Lineage C (Seed 15) 5.1 Dependencies 5.2 Loading data 5.3 Lineage data 5.4 Replay data", " Section 5 Lineage C (Seed 15) Here we plot more details of Lineage C than would fit in the paper. If you are looking through the experiment files, Lineage C was seed 15. All data for Lineage C can be found in the data/reps/15/ directory. 5.1 Dependencies rm(list = ls()) # External library(ggplot2) library(dplyr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) # Configuration variables base_repo_dir = &#39;../..&#39; exp_dir = paste0(base_repo_dir, &#39;/experiments/alife_2023/2023_02_21_01__initial_10_cooldown&#39;) seed = 15 potentiation_window_start = 250 potentiation_window_stop = 300 potentiation_target = 279 # Internal source(paste0(base_repo_dir, &#39;/global_shared_files/constant_vars__three_cues_one_set.R&#39;)) source(paste0(base_repo_dir, &#39;/global_shared_files/shared_funcs__three_cues_one_set.R&#39;)) 5.2 Loading data To save time, we load the pre-processed data. To see how the data gets processed, please see ./analysis/replay_analysis.R from the experiment directory. # Data for all trials from all replay replicates df = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_data.csv&#39;)) # One line per replay replicate that summarizes all 100 trials df_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_summary.csv&#39;)) # Sumamrize each category, e.g., how many replicates evolved error correction? classification_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_classification.csv&#39;)) # Also grab lineage data df_lineage = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/dominant_lineage_summary.csv&#39;)) # Because lineage data was collected on the cluster before we renamed a few classifications, rename them now! df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification_factor = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification_factor = seed_class_small df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification = seed_class_small 5.3 Lineage data While not shown in the paper due to space limitations, it is important to look at the initial replicate’s lineage and how it changes over time. The code for these plots is copied from the single_seed_lineage_analysis.R script. 5.3.1 Merit First, we look at the lineage as a whole and how average merit changes over time (note the y-axis is logarithmic) ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 0.25) + scale_y_continuous(trans = &#39;log2&#39;) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) Additionally, we can zoom in to view just the potentiation window. The vertical dashed line shows the main potentiating step, step 279, while the horizontal dashed line shows average merit at that step for easier comparisons. Note that this plot is not logarithmic. potentiation_mask = df_lineage$depth &gt;= potentiation_window_start &amp; df_lineage$depth &lt;= potentiation_window_stop target_step_merit_mean = df_lineage[df_lineage$depth == potentiation_target,]$merit_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_merit_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) We see a drastic drop in merit at the potentiating mutation. Merit does increase to an even higher point a few steps after the potentiating mutation, however. We can also normalize the merit based on the potentiating step. Remember that one additional correct state confers a merit bonus of 10%. Here, we can see that merit was over 2,000 times higher before the potentiating mutation. ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = 1), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean / target_step_merit_mean)) + geom_point(aes(y = merit_mean / target_step_merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) 5.3.2 Correct states Similarly, we can look at the number of correct states both overall and in the potentiation window: Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window (dashed lines show the main potentiating mutation): target_step_correct_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$correct_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_correct_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) We see a noticable drop in correct states at the potentiating mutation, and we also see the increase in correct states a few steps later. 5.3.3 Incorrect states Just like our analysis of correct states, we can also look at the average incorrect states over time. By incorrect states, we mean the wrong movements while in a left, right, or forward state. Incorrect movements from a backward state are tracked separately. Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window: target_step_incorrect_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$incorrect_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_incorrect_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) We see an increase in incorrect states at the potentiating mutation, but only to an average of 1. 5.4 Replay data Now that we know what the lineage looks like, we can begin to break down the replay data. 5.4.1 Exploratory replays We started by seeding 50 replay replicates for every 50th step along the lineage in the window [50, 1000]. The data for step 0 comes from the initial 200 replicates. Here we show the potentiation over time for those exploratory replays: df_learning_summary = classification_summary[classification_summary$seed_classification == seed_class_learning,] df_learning_summary$lineage_classification = NA # Assign each depth its classification from the lineage data for(depth in unique(df_learning_summary$depth)){ df_learning_summary[df_learning_summary$depth == depth,]$lineage_classification = df_lineage[df_lineage$depth == depth,]$seed_classification } # Create masks mask_learning_summary_focal = df_learning_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_learning_summary_initial = df_learning_summary$depth %% 50 == 0 ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) We can then identify the potentiation window based on the points with the most potentiation gain. Here we selected steps 250-300 (green shaded region): ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) 5.4.2 Targeted replays With the potentiation window identified, we seeded targeted replays. For the targeted replays, we seeded 50 replay replicates from every step in the potetiation window. This gives us an idea of how individual steps in the phylogney affected potentiation. ggplot(df_learning_summary[mask_learning_summary_focal,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dotted&#39;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) This plot was extensively discussed in the paper, so we refrain from additional discussion here. 5.4.3 Potentiation of other behaviors While the paper mostly focused on learning, it can be useful to see how the potentiation of other behaviors changes before learning takes over. These plots are included as inspiration for future work. mask_focal = classification_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_initial = classification_summary$depth %% 50 == 0 ggplot(classification_summary[mask_initial,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here is the same data, but plotted as an area plot: ggplot(classification_summary[mask_initial,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here are the same two plots showing the potentiation window and the targeted replays: ggplot(classification_summary[mask_focal,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) ggplot(classification_summary[mask_focal,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) "],["lineage-d-seed-6.html", "Section 6 Lineage D (Seed 6) 6.1 Dependencies 6.2 Loading data 6.3 Lineage data 6.4 Replay data", " Section 6 Lineage D (Seed 6) Here we plot more details of Lineage D than would fit in the paper. If you are looking through the experiment files, Lineage D was seed 6. All data for Lineage D can be found in the data/reps/6/ directory. 6.1 Dependencies rm(list = ls()) # External library(ggplot2) library(dplyr) source(&quot;https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R&quot;) # Configuration variables base_repo_dir = &#39;../..&#39; exp_dir = paste0(base_repo_dir, &#39;/experiments/alife_2023/2023_02_21_01__initial_10_cooldown&#39;) seed = 6 potentiation_window_start = 500 potentiation_window_stop = 550 potentiation_target = 548 # Internal source(paste0(base_repo_dir, &#39;/global_shared_files/constant_vars__three_cues_one_set.R&#39;)) source(paste0(base_repo_dir, &#39;/global_shared_files/shared_funcs__three_cues_one_set.R&#39;)) 6.2 Loading data To save time, we load the pre-processed data. To see how the data gets processed, please see ./analysis/replay_analysis.R from the experiment directory. # Data for all trials from all replay replicates df = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_data.csv&#39;)) # One line per replay replicate that summarizes all 100 trials df_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_summary.csv&#39;)) # Sumamrize each category, e.g., how many replicates evolved error correction? classification_summary = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/replays/processed_data/processed_replay_classification.csv&#39;)) # Also grab lineage data df_lineage = read.csv(paste0(exp_dir, &#39;/data/reps/&#39;, seed, &#39;/dominant_lineage_summary.csv&#39;)) # Because lineage data was collected on the cluster before we renamed a few classifications, rename them now! # Note: no seeds were classified as bet-hedged learning, so we must skip these lines #df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification_factor = seed_class_bet_hedged_learning #df_lineage[df_lineage$seed_classification == &#39;Bet-hedged imprinting&#39;,]$seed_classification = seed_class_bet_hedged_learning df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification_factor = seed_class_small df_lineage[df_lineage$seed_classification == &#39;Small&#39;,]$seed_classification = seed_class_small 6.3 Lineage data While not shown in the paper due to space limitations, it is important to look at the initial replicate’s lineage and how it changes over time. The code for these plots is copied from the single_seed_lineage_analysis.R script. 6.3.1 Merit First, we look at the lineage as a whole and how average merit changes over time (note the y-axis is logarithmic) ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 0.25) + scale_y_continuous(trans = &#39;log2&#39;) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) Additionally, we can zoom in to view just the potentiation window. The vertical dashed line shows the main potentiating step, step 548, while the horizontal dashed line shows average merit at that step for easier comparisons. Note that this plot is not logarithmic. potentiation_mask = df_lineage$depth &gt;= potentiation_window_start &amp; df_lineage$depth &lt;= potentiation_window_stop target_step_merit_mean = df_lineage[df_lineage$depth == potentiation_target,]$merit_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_merit_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean)) + geom_point(aes(y = merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) We do not see drastic differences in fitness around step 484. We can also normalize the merit based on the potentiating step. Remember that one additional correct state confers a merit bonus of 10%. Here, we do see a slight increase in merit. ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = 1), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = merit_mean / target_step_merit_mean)) + geom_point(aes(y = merit_mean / target_step_merit_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean merit&#39;) + xlab(&#39;Phylogenetic step&#39;) 6.3.2 Correct states Similarly, we can look at the number of correct states both overall and in the potentiation window: Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window (dashed lines show the main potentiating mutation): target_step_correct_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$correct_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_correct_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = correct_doors_mean)) + geom_point(aes(y = correct_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean correct states&#39;) + xlab(&#39;Phylogenetic step&#39;) We see no noticable change in the number of correct states around the potentiating mutation. 6.3.3 Incorrect states Just like our analysis of correct states, we can also look at the average incorrect states over time. By incorrect states, we mean the wrong movements while in a left, right, or forward state. Incorrect movements from a backward state are tracked separately. Overall: ggplot(df_lineage, aes(x = depth)) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 0.25) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) Potentiation window: target_step_incorrect_doors_mean = df_lineage[df_lineage$depth == potentiation_target,]$incorrect_doors_mean ggplot(df_lineage[potentiation_mask,], aes(x = depth)) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_hline(aes(yintercept = target_step_incorrect_doors_mean), linetype = &#39;dashed&#39;, alpha = 0.5) + geom_line(aes(y = incorrect_doors_mean)) + geom_point(aes(y = incorrect_doors_mean, color = seed_classification), size = 1) + scale_color_manual(values = color_map) + theme(axis.text = element_text(size = 10)) + theme(axis.title = element_text(size = 12)) + labs(color = &#39;Classification&#39;) + ylab(&#39;Mean incorrect states&#39;) + xlab(&#39;Phylogenetic step&#39;) We do see a noticeable decrease in the average number of incorrect states at the potentiating mutation. Also, in the full plot, we can see the clear shift from error correction to learning when the number of incorrect states quickly drops to 0. 6.4 Replay data Now that we know what the lineage looks like, we can begin to break down the replay data. 6.4.1 Exploratory replays We started by seeding 50 replay replicates for every 50th step along the lineage in the window [50, 1000]. The data for step 0 comes from the initial 200 replicates. Here we show the potentiation over time for those exploratory replays: df_learning_summary = classification_summary[classification_summary$seed_classification == seed_class_learning,] df_learning_summary$lineage_classification = NA # Assign each depth its classification from the lineage data for(depth in unique(df_learning_summary$depth)){ df_learning_summary[df_learning_summary$depth == depth,]$lineage_classification = df_lineage[df_lineage$depth == depth,]$seed_classification } # Create masks mask_learning_summary_focal = df_learning_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_learning_summary_initial = df_learning_summary$depth %% 50 == 0 ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) We can then identify the potentiation window based on the points with the most potentiation gain. Here we selected steps 500-550 (green shaded region): ggplot(df_learning_summary[mask_learning_summary_initial,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) 6.4.2 Targeted replays With the potentiation window identified, we seeded targeted replays. For the targeted replays, we seeded 50 replay replicates from every step in the potetiation window. This gives us an idea of how individual steps in the phylogney affected potentiation. ggplot(df_learning_summary[mask_learning_summary_focal,], aes(x=depth)) + annotate(&quot;rect&quot;, xmin=potentiation_window_start, xmax=potentiation_window_stop, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;#64e164&quot;) + geom_vline(aes(xintercept = potentiation_target), linetype = &#39;dotted&#39;) + geom_line(mapping=aes(y = frac*100), size = 1.05) + geom_point(mapping=aes(y = frac*100, color = as.factor(lineage_classification)), size = 2.5) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,100)) + xlab(&#39;Phylogenetic step&#39;) + ylab(&#39;Percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) + theme(legend.position = &#39;none&#39;) This plot was extensively discussed in the paper, so we refrain from additional discussion here. 6.4.3 Potentiation of other behaviors While the paper mostly focused on learning, it can be useful to see how the potentiation of other behaviors changes before learning takes over. These plots are included as inspiration for future work. mask_focal = classification_summary$depth %in% potentiation_window_start:potentiation_window_stop mask_initial = classification_summary$depth %% 50 == 0 ggplot(classification_summary[mask_initial,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here is the same data, but plotted as an area plot: ggplot(classification_summary[mask_initial,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) Here are the same two plots showing the potentiation window and the targeted replays: ggplot(classification_summary[mask_focal,], aes(x=depth, color = seed_classification_factor)) + geom_line(mapping=aes(y = frac), size=1.2) + geom_point(mapping=aes(y = frac), size = 2) + scale_color_manual(values = color_map) + scale_fill_manual(values = color_map) + scale_y_continuous(limits = c(-0.1,1)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(color = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) ggplot(classification_summary[mask_focal,], aes(x = depth, y = frac, fill = seed_classification_factor)) + geom_area() + scale_fill_manual(values = color_map) + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + xlab(&#39;phylogenetic step&#39;) + ylab(&#39;percentage of replays that evolve learning&#39;) + labs(fill = &#39;Classification&#39;) + theme(axis.text = element_text(size = 12)) + theme(axis.title = element_text(size = 14)) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
